{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run FunSearch on Bin Packing\n",
    "Five steps:\n",
    "1. Implement 'LLM' interface.\n",
    "2. Implement a 'SandBox' interface.\n",
    "3. Prepare a 'specification'.\n",
    "4. Prepare a dataset.\n",
    "5. Start FunSearch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ba1915fced4e72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation: download the project file from github. And update system path."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2d02b8e9c3ba67"
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/RayZhhh/funsearch.git\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/funsearch/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:13:06.533150Z",
     "start_time": "2024-08-01T03:10:25.072376Z"
    }
   },
   "id": "22453e8153e0934c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'funsearch'...\r\n",
      "error: RPC failed; curl 28 Failed to connect to github.com port 443: Connection timed out\r\n",
      "fatal: the remote end hung up unexpectedly\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Implement LLM interface\n",
    "Set the API's IP address according to your API provider (See line 65 in the following code).\n",
    "```python\n",
    "conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "```\n",
    "You should prepare a 'key' for the LLM API. And fill them in the header (See line 76-80 in the following code).\n",
    "```python\n",
    "headers = {\n",
    "    'Authorization': 'Bearer [put your key here, the key may start with \"sk-...\"]',\n",
    "    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe47175708cc0a93"
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/xtanghao/THPycharm/AEL_main/baseline/funsearch\")\n",
    "\n",
    "import time\n",
    "import json\n",
    "import multiprocessing\n",
    "from typing import Collection, Any\n",
    "import http.client\n",
    "from implementation import sampler\n",
    "\n",
    "\n",
    "def _trim_preface_of_body(sample: str) -> str:\n",
    "    \"\"\"Trim the redundant descriptions/symbols/'def' declaration before the function body.\n",
    "    Please see my comments in sampler.LLM (in sampler.py).\n",
    "    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.\n",
    "\n",
    "    -Example sample (function & description generated by LLM):\n",
    "    -------------------------------------\n",
    "    This is the optimized function ...\n",
    "    def priority_v2(...) -> ...:\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    -This function removes the description above the function's signature, and the function's signature.\n",
    "    -The indent of the code is preserved.\n",
    "    -Return of this function:\n",
    "    -------------------------------------\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    \"\"\"\n",
    "    lines = sample.splitlines()\n",
    "    func_body_lineno = 0\n",
    "    find_def_declaration = False\n",
    "    for lineno, line in enumerate(lines):\n",
    "        # find the first 'def' statement in the given code\n",
    "        if line[:3] == 'def':\n",
    "            func_body_lineno = lineno\n",
    "            find_def_declaration = True\n",
    "            break\n",
    "    if find_def_declaration:\n",
    "        code = ''\n",
    "        for line in lines[func_body_lineno + 1:]:\n",
    "            code += line + '\\n'\n",
    "        return code\n",
    "    return sample\n",
    "\n",
    "\n",
    "class LLMAPI(sampler.LLM):\n",
    "    \"\"\"Language model that predicts continuation of provided source code.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples_per_prompt: int, trim=True):\n",
    "        super().__init__(samples_per_prompt)\n",
    "        additional_prompt = ('Complete a different and more complex Python function. '\n",
    "                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'\n",
    "                             'Only output the Python code, no descriptions.')\n",
    "        self._additional_prompt = additional_prompt\n",
    "        self._trim = trim\n",
    "\n",
    "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
    "        \"\"\"Returns multiple predicted continuations of `prompt`.\"\"\"\n",
    "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
    "\n",
    "    def _draw_sample(self, content: str) -> str:\n",
    "        prompt = '\\n'.join([content, self._additional_prompt])\n",
    "        while True:\n",
    "            try:\n",
    "                conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "                payload = json.dumps({\n",
    "                    \"max_tokens\": 512,\n",
    "                    \"model\": \"gpt-3.5-turbo\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "                headers = {\n",
    "                    'Authorization': 'Bearer sk-ys02zx......(replace with your own)......',\n",
    "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "                    'Content-Type': 'application/json'\n",
    "                }\n",
    "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                data = json.loads(data)\n",
    "                response = data['choices'][0]['message']['content']\n",
    "                # trim function\n",
    "                if self._trim:\n",
    "                    response = _trim_preface_of_body(response)\n",
    "                return response\n",
    "            except Exception:\n",
    "                time.sleep(2)\n",
    "                continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:17:36.673184Z",
     "start_time": "2024-08-01T03:17:36.585903Z"
    }
   },
   "id": "1999e45c9a568b08",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Implement a 'SandBox' interface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d27817cdec2cedfc"
  },
  {
   "cell_type": "code",
   "source": [
    "from implementation import evaluator\n",
    "from implementation import evaluator_accelerate\n",
    "\n",
    "\n",
    "class Sandbox(evaluator.Sandbox):\n",
    "    \"\"\"Sandbox for executing generated code. Implemented by RZ.\n",
    "\n",
    "    RZ: Sandbox returns the 'score' of the program and:\n",
    "    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).\n",
    "    2) stops the execution of the code in time (avoid endless loop).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=False, numba_accelerate=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            verbose         : Print evaluate information.\n",
    "            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions\n",
    "                              support numba acceleration, such as np.piecewise().\n",
    "        \"\"\"\n",
    "        self._verbose = verbose\n",
    "        self._numba_accelerate = numba_accelerate\n",
    "\n",
    "    def run(\n",
    "            self,\n",
    "            program: str,\n",
    "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
    "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
    "            inputs: Any,  # refers to the dataset\n",
    "            test_input: str,  # refers to the current instance\n",
    "            timeout_seconds: int,\n",
    "            **kwargs  # RZ: add this\n",
    "    ) :\n",
    "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
    "\n",
    "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
    "        the output of this function is the score of a given program.\n",
    "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
    "        \"\"\"\n",
    "        dataset = inputs[test_input]\n",
    "        try:\n",
    "            result_queue = multiprocessing.Queue()\n",
    "            process = multiprocessing.Process(\n",
    "                target=self._compile_and_run_function,\n",
    "                args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
    "            )\n",
    "            process.start()\n",
    "            process.join(timeout=timeout_seconds)\n",
    "            if process.is_alive():\n",
    "                # if the process is not finished in time, we consider the program illegal\n",
    "                process.terminate()\n",
    "                process.join()\n",
    "                results = None, False\n",
    "            else:\n",
    "                if not result_queue.empty():\n",
    "                    results = result_queue.get_nowait()\n",
    "                else:\n",
    "                    results = None, False\n",
    "\n",
    "            return results\n",
    "        except:\n",
    "            return None, False\n",
    "\n",
    "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
    "                                  result_queue):\n",
    "        try:\n",
    "            # optimize the code (decorate function_to_run with @numba.jit())\n",
    "            if numba_accelerate:\n",
    "                program = evaluator_accelerate.add_numba_decorator(\n",
    "                    program=program,\n",
    "                    function_to_evolve=function_to_evolve\n",
    "                )\n",
    "            # compile the program, and maps the global func/var/class name to its address\n",
    "            all_globals_namespace = {}\n",
    "            # execute the program, map func/var/class to global namespace\n",
    "            exec(program, all_globals_namespace)\n",
    "            # get the pointer of 'function_to_run'\n",
    "            function_to_run = all_globals_namespace[function_to_run]\n",
    "            # return the execution results\n",
    "            results = function_to_run(dataset)\n",
    "            # the results must be int or float\n",
    "            if not isinstance(results, (int, float)):\n",
    "                result_queue.put((None, False))\n",
    "                return\n",
    "            result_queue.put((results, True))\n",
    "        except Exception:\n",
    "            # if raise any exception, we assume the execution failed\n",
    "            result_queue.put((None, False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:18:32.008629Z",
     "start_time": "2024-08-01T03:18:31.990313Z"
    }
   },
   "id": "3e3d88a87535b6b2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prepare a 'specification'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3a05827354f9ae"
  },
  {
   "cell_type": "code",
   "source": [
    "specification = r'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
    "    return np.nonzero((bins - item) >= 0)[0]\n",
    "\n",
    "\n",
    "def online_binpack(\n",
    "        items: tuple[float, ...], bins: np.ndarray\n",
    ") -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "    \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
    "    # Track which items are added to each bin.\n",
    "    packing = [[] for _ in bins]\n",
    "    # Add items to bins.\n",
    "    for item in items:\n",
    "        # Extract bins that have sufficient space to fit item.\n",
    "        valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "        # Score each bin based on heuristic.\n",
    "        priorities = priority(item, bins[valid_bin_indices])\n",
    "        # Add item to bin with highest priority.\n",
    "        best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "        bins[best_bin] -= item\n",
    "        packing[best_bin].append(item)\n",
    "    # Remove unused bins from packing.\n",
    "    packing = [bin_items for bin_items in packing if bin_items]\n",
    "    return packing, bins\n",
    "\n",
    "\n",
    "@funsearch.run\n",
    "def evaluate(instances: dict) -> float:\n",
    "    \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
    "    # List storing number of bins used for each instance.\n",
    "    num_bins = []\n",
    "    # Perform online binpacking for each instance.\n",
    "    for name in instances:\n",
    "        instance = instances[name]\n",
    "        capacity = instance['capacity']\n",
    "        items = instance['items']\n",
    "        # Create num_items bins so there will always be space for all items,\n",
    "        # regardless of packing order. Array has shape (num_items,).\n",
    "        bins = np.array([capacity for _ in range(instance['num_items'])])\n",
    "        # Pack items into bins and return remaining capacity in bins_packed, which\n",
    "        # has shape (num_items,).\n",
    "        _, bins_packed = online_binpack(items, bins)\n",
    "        # If remaining capacity in a bin is equal to initial capacity, then it is\n",
    "        # unused. Count number of used bins.\n",
    "        num_bins.append((bins_packed != capacity).sum())\n",
    "    # Score of heuristic function is negative of average number of bins used\n",
    "    # across instances (as we want to minimize number of bins).\n",
    "    return -np.mean(num_bins)\n",
    "\n",
    "\n",
    "@funsearch.evolve\n",
    "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns priority with which we want to add item to each bin.\n",
    "\n",
    "    Args:\n",
    "        item: Size of item to be added to the bin.\n",
    "        bins: Array of capacities for each bin.\n",
    "\n",
    "    Return:\n",
    "        Array of same size as bins with priority score of each bin.\n",
    "    \"\"\"\n",
    "    ratios = item / bins\n",
    "    log_ratios = np.log(ratios)\n",
    "    priorities = -log_ratios\n",
    "    return priorities\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:18:40.664019Z",
     "start_time": "2024-08-01T03:18:40.657062Z"
    }
   },
   "id": "2e2f875d128a693a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Prepare a dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "391bfe61e1661e18"
  },
  {
   "cell_type": "code",
   "source": [
    "import bin_packing_utils\n",
    "\n",
    "bin_packing_or3 = {'OR3': bin_packing_utils.datasets['OR3']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:18:46.109871Z",
     "start_time": "2024-08-01T03:18:46.037738Z"
    }
   },
   "id": "fea85ccfc8c0ca6d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Start FunSearch\n",
    "Please note that in jupyter notebook the following code will fail. This is because juypter does not support multiprocessing. Colab backend supports multiprocessing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb66651fb2764ce9"
  },
  {
   "cell_type": "code",
   "source": [
    "from implementation import funsearch\n",
    "from implementation import config\n",
    "\n",
    "# It should be noted that the if __name__ == '__main__' is required.\n",
    "# Because the inner code uses multiprocess evaluation.\n",
    "if __name__ == '__main__':\n",
    "    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
    "    config = config.Config(samples_per_prompt=4)\n",
    "    global_max_sample_num = 10  # if it is set to None, funsearch will execute an endless loop\n",
    "    funsearch.main(\n",
    "        specification=specification,\n",
    "        inputs=bin_packing_or3,\n",
    "        config=config,\n",
    "        max_sample_nums=global_max_sample_num,\n",
    "        class_config=class_config,\n",
    "        log_dir='../logs/funsearch_llm_api'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-01T03:28:42.252184Z",
     "start_time": "2024-08-01T03:28:42.210282Z"
    }
   },
   "id": "1e0ec0c796d09ca1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Failed parsing \n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
      "    return np.nonzero((bins - item) >= 0)[0]\n",
      "\n",
      "\n",
      "def online_binpack(\n",
      "        items: tuple[float, ...], bins: np.ndarray\n",
      ") -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
      "    \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
      "    # Track which items are added to each bin.\n",
      "    packing = [[] for _ in bins]\n",
      "    # Add items to bins.\n",
      "    for item in items:\n",
      "        # Extract bins that have sufficient space to fit item.\n",
      "        valid_bin_indices = get_valid_bin_indices(item, bins)\n",
      "        # Score each bin based on heuristic.\n",
      "        priorities = priority(item, bins[valid_bin_indices])\n",
      "        # Add item to bin with highest priority.\n",
      "        best_bin = valid_bin_indices[np.argmax(priorities)]\n",
      "        bins[best_bin] -= item\n",
      "        packing[best_bin].append(item)\n",
      "    # Remove unused bins from packing.\n",
      "    packing = [bin_items for bin_items in packing if bin_items]\n",
      "    return packing, bins\n",
      "\n",
      "\n",
      "@funsearch.run\n",
      "def evaluate(instances: dict) -> float:\n",
      "    \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
      "    # List storing number of bins used for each instance.\n",
      "    num_bins = []\n",
      "    # Perform online binpacking for each instance.\n",
      "    for name in instances:\n",
      "        instance = instances[name]\n",
      "        capacity = instance['capacity']\n",
      "        items = instance['items']\n",
      "        # Create num_items bins so there will always be space for all items,\n",
      "        # regardless of packing order. Array has shape (num_items,).\n",
      "        bins = np.array([capacity for _ in range(instance['num_items'])])\n",
      "        # Pack items into bins and return remaining capacity in bins_packed, which\n",
      "        # has shape (num_items,).\n",
      "        _, bins_packed = online_binpack(items, bins)\n",
      "        # If remaining capacity in a bin is equal to initial capacity, then it is\n",
      "        # unused. Count number of used bins.\n",
      "        num_bins.append((bins_packed != capacity).sum())\n",
      "    # Score of heuristic function is negative of average number of bins used\n",
      "    # across instances (as we want to minimize number of bins).\n",
      "    return -np.mean(num_bins)\n",
      "\n",
      "\n",
      "@funsearch.evolve\n",
      "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"Returns priority with which we want to add item to each bin.\n",
      "\n",
      "    Args:\n",
      "        item: Size of item to be added to the bin.\n",
      "        bins: Array of capacities for each bin.\n",
      "\n",
      "    Return:\n",
      "        Array of same size as bins with priority score of each bin.\n",
      "    \"\"\"\n",
      "    ratios = item / bins\n",
      "    log_ratios = np.log(ratios)\n",
      "    priorities = -log_ratios\n",
      "    return priorities\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'ast' has no attribute 'unparse'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mConfig(samples_per_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m      9\u001B[0m global_max_sample_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m  \u001B[38;5;66;03m# if it is set to None, funsearch will execute an endless loop\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mfunsearch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspecification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspecification\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbin_packing_or3\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_sample_nums\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mglobal_max_sample_num\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../logs/funsearch_llm_api\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     17\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/THPycharm/AEL_main/baseline/funsearch/implementation/funsearch.py:68\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(specification, inputs, config, max_sample_nums, class_config, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Launches a FunSearch experiment.\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03mRZ:\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    max_sample_nums: the maximum samples nums from LLM. 'None' refers to no stop.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m function_to_evolve, function_to_run \u001B[38;5;241m=\u001B[39m _extract_function_names(specification)\n\u001B[0;32m---> 68\u001B[0m template \u001B[38;5;241m=\u001B[39m \u001B[43mcode_manipulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_to_program\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspecification\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m database \u001B[38;5;241m=\u001B[39m programs_database\u001B[38;5;241m.\u001B[39mProgramsDatabase(config\u001B[38;5;241m.\u001B[39mprograms_database, template, function_to_evolve)\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# get log_dir and create profiler\u001B[39;00m\n",
      "File \u001B[0;32m~/THPycharm/AEL_main/baseline/funsearch/implementation/code_manipulation.py:194\u001B[0m, in \u001B[0;36mtext_to_program\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    193\u001B[0m     logging\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed parsing \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/THPycharm/AEL_main/baseline/funsearch/implementation/code_manipulation.py:190\u001B[0m, in \u001B[0;36mtext_to_program\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m    188\u001B[0m     tree \u001B[38;5;241m=\u001B[39m ast\u001B[38;5;241m.\u001B[39mparse(text)\n\u001B[1;32m    189\u001B[0m     visitor \u001B[38;5;241m=\u001B[39m ProgramVisitor(text)\n\u001B[0;32m--> 190\u001B[0m     \u001B[43mvisitor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtree\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m visitor\u001B[38;5;241m.\u001B[39mreturn_program()\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/ast.py:371\u001B[0m, in \u001B[0;36mNodeVisitor.visit\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    369\u001B[0m method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvisit_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m node\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m    370\u001B[0m visitor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, method, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneric_visit)\n\u001B[0;32m--> 371\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvisitor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/ast.py:379\u001B[0m, in \u001B[0;36mNodeVisitor.generic_visit\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m value:\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, AST):\n\u001B[0;32m--> 379\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, AST):\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvisit(value)\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/ast.py:371\u001B[0m, in \u001B[0;36mNodeVisitor.visit\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    369\u001B[0m method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvisit_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m node\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m    370\u001B[0m visitor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, method, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneric_visit)\n\u001B[0;32m--> 371\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvisitor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/THPycharm/AEL_main/baseline/funsearch/implementation/code_manipulation.py:163\u001B[0m, in \u001B[0;36mProgramVisitor.visit_FunctionDef\u001B[0;34m(self, node)\u001B[0m\n\u001B[1;32m    161\u001B[0m docstring \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node\u001B[38;5;241m.\u001B[39mbody[\u001B[38;5;241m0\u001B[39m], ast\u001B[38;5;241m.\u001B[39mExpr) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node\u001B[38;5;241m.\u001B[39mbody[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue, ast\u001B[38;5;241m.\u001B[39mStr):\n\u001B[0;32m--> 163\u001B[0m     docstring \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mast\u001B[38;5;241m.\u001B[39mliteral_eval(ast\u001B[38;5;241m.\u001B[39munparse(node\u001B[38;5;241m.\u001B[39mbody[\u001B[38;5;241m0\u001B[39m]))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(node\u001B[38;5;241m.\u001B[39mbody) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    165\u001B[0m         body_start_line \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mbody[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mlineno \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'ast' has no attribute 'unparse'"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
