/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Results folders created successfully!
>>> Start AEL 
begin evaluate
['results', 'joao.sh', 'runAEL_laug.py', '__pycache__', 'th_llm', 'joao.py', 'nohup.out', 'joaov2_aug.py', 'joaov2.sh', 'ael_prompts.py', 'ael_seeds', 'evaluate_embedding.py', 'aug.py', 'ael_alg.py', 'test.py', 'joaov2_laug.py', 'joaov2_no_aug.py', 'joaov2.py', 'runAEL.py', 'ael_evaluation.py', 'add.py', 'data', 'arguments.py', 'model.py', 'gin.py', 'README.md', 'ael_results', 'th_nodes.txt']
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8982, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8518, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6942, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5163, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.3917912774616
cccccc
ddddddd
eeeeeee
0.7788321167883211 0.7805352798053528
{'val': [0.7788321167883211], 'test': [0.7805352798053528]}
0
1
2
3
4
[5.84837055 5.86596513 5.83981967 5.85897946 5.86875582] [0.19193083 0.20966074 0.18331418 0.20262135 0.2124729 ]
evaluate a time: 4.833333333333333 m
0.21946472019464724
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8982, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8518, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6942, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5160, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.392479631636
cccccc
ddddddd
eeeeeee
0.7793187347931874 0.7793187347931874
{'val': [0.7793187347931874], 'test': [0.7793187347931874]}
0
1
2
3
4
[5.84856439 5.86596107 5.83980799 5.85913563 5.86898756] [0.19201099 0.2095439  0.18318602 0.20266501 0.21259408]
evaluate a time: 5.05 m
0.22068126520681264
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8982, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8518, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6942, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5163, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.3922732406193
cccccc
ddddddd
eeeeeee
0.778588807785888 0.778588807785888
{'val': [0.778588807785888], 'test': [0.778588807785888]}
0
1
2
3
4
[5.84685898 5.86438155 5.83822632 5.85745478 5.8673563 ] [0.19193984 0.20960167 0.18323857 0.20261985 0.21260007]
evaluate a time: 5.183333333333334 m
0.22141119221411198
Initiliazation finished! Get 3 seed algorithms
test population generation seed time: 15.083333333333334 m
write back seeds done.
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6109, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5229, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4226, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9009826713138
cccccc
ddddddd
eeeeeee
0.7812652068126521 0.7746958637469586
{'val': [0.7812652068126521], 'test': [0.7746958637469586]}
0
1
2
3
4
[6.13307786 6.1330781  6.1330781  6.1330781  6.1330781 ] [0.19999981 0.20000005 0.20000005 0.20000005 0.20000005]
generate new algorithm using e1 with fitness value:  0.2253
evolution 1 cost time: 4.75 m
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8516, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6921, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5280, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.246929883957
cccccc
ddddddd
eeeeeee
Error in API. 
0.781021897810219 0.7822384428223844
{'val': [0.781021897810219], 'test': [0.7822384428223844]}
0
1
2
3
4
[5.8656249  5.88218737 5.8567543  5.87720871 5.88636518] [0.19193093 0.20862974 0.1829873  0.20361009 0.21284194]
generate new algorithm using m1 with fitness value:  0.21776
evolution 1 cost time: 6.5 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
Error: 'numpy.ndarray' object has no attribute 'unsqueeze'
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The shape of the mask [7] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The size of tensor a (7) must match the size of tensor b (2) at non-singleton dimension 0
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4455, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3896, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2147, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9589, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.6287432379193
cccccc
ddddddd
eeeeeee
0.7829683698296837 0.7858880778588808
{'val': [0.7829683698296837], 'test': [0.7858880778588808]}
0
1
2
3
4
[5.90678644 5.91870403 5.91490412 5.9247489  5.9262414 ] [0.18860987 0.20042332 0.19665661 0.20641537 0.20789483]
generate new algorithm using e1 with fitness value:  0.21411
evolution 1 cost time: 5.85 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
Error in API. 
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9579, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.64662249883
cccccc
ddddddd
eeeeeee
Error in API. 
0.7856447688564476 0.7856447688564476
{'val': [0.7856447688564476], 'test': [0.7856447688564476]}
0
1
2
3
4
[5.91090178 5.92288041 5.91921115 5.92887998 5.93069816] [0.18848618 0.200363   0.19672493 0.20631158 0.20811431]
generate new algorithm using m1 with fitness value:  0.21436
evolution 1 cost time: 5.816666666666666 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8516, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6923, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
tensor(3.6693, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5306, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.233838306533
cccccc
ddddddd
eeeeeee
0.7800486618004866 0.783698296836983
{'val': [0.7800486618004866], 'test': [0.783698296836983]}
0
1
2
3
4
[5.86214733 5.8791151  5.85369086 5.87367821 5.88280416] [0.19179457 0.20889915 0.18326993 0.20341841 0.21261794]
generate new algorithm using e1 with fitness value:  0.2163
evolution 1 cost time: 5.116666666666666 m
starting new request...
NCI1
4110
37
Error: 'int' object has no attribute 'item'
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.8364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1886, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0908, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1966.7500150352716
cccccc
ddddddd
eeeeeee
0.7883211678832117 0.7839416058394162
{'val': [0.7883211678832117], 'test': [0.7839416058394162]}
0
1
2
3
4
[5.88696504 5.89178348 5.8921473  5.88742352 5.8928287 ] [0.19674085 0.20155129 0.20191451 0.19719857 0.20259478]
generate new algorithm using m1 with fitness value:  0.21606
evolution 1 cost time: 5.1 m
>> 3 of 3 finished 
fitness values of current population: 
0.21411 
0.21436 
0.21606 
>>> 1 of 3 populations finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.8364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1888, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0817, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0478, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0845, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1966.379818181197
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7873479318734794 0.7834549878345498
{'val': [0.7873479318734794], 'test': [0.7834549878345498]}
0
1
2
3
4
[5.88468289 5.89009333 5.89054084 5.88592696 5.8910656 ] [0.19623204 0.20162662 0.20207282 0.19747247 0.20259605]
generate new algorithm using e1 with fitness value:  0.21655
evolution 1 cost time: 8.2 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(5.3615, device='cuda:0', grad_fn=<NegBackward0>)
tensor(5.2404, device='cuda:0', grad_fn=<NegBackward0>)
tensor(5.0169, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.8420, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9264, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7750, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7484, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.1730, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 2269.0214603741965
cccccc
ddddddd
eeeeeee
Error in API. 
0.7688564476885644 0.7710462287104624
{'val': [0.7688564476885644], 'test': [0.7710462287104624]}
0
1
2
3
4
[6.0422194  6.04348779 6.04141378 6.0463407  6.04893589] [0.197732   0.19900481 0.19692358 0.20186768 0.20447192]
generate new algorithm using m1 with fitness value:  0.22895
evolution 1 cost time: 4.866666666666666 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.8364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1886, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0910, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1966.7509139080842
cccccc
ddddddd
eeeeeee
Error in API. 
0.7880778588807785 0.7839416058394161
{'val': [0.7880778588807785], 'test': [0.7839416058394161]}
0
1
2
3
4
[5.88715029 5.89198875 5.89230156 5.88762403 5.89296389] [0.19675025 0.2015803  0.20189256 0.19722316 0.20255373]
duplicated result, retrying ... 
generate new algorithm using e1 with fitness value:  0.21606
evolution 1 cost time: 4.833333333333333 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
tensor(5.3615, device='cuda:0', grad_fn=<NegBackward0>)
tensor(5.2404, device='cuda:0', grad_fn=<NegBackward0>)
tensor(5.0169, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.8420, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9264, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7733, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7477, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.1444, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 2268.8392541938356
cccccc
ddddddd
eeeeeee
0.767396593673966 0.770316301703163
{'val': [0.767396593673966], 'test': [0.770316301703163]}
0
1
2
3
4
[6.04714203 6.04845285 6.04634261 6.05131102 6.05417204] [0.19764883 0.19896474 0.19684631 0.201834   0.20470612]
generate new algorithm using m1 with fitness value:  0.22968
evolution 1 cost time: 5.183333333333334 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6106, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4233, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.8985453446705
cccccc
ddddddd
eeeeeee
0.7815085158150852 0.7734793187347933
{'val': [0.7815085158150852], 'test': [0.7734793187347933]}
0
1
2
3
4
[6.13164711 6.13164711 6.13164711 6.13164711 6.13164711] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22652
evolution 1 cost time: 4.75 m
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9231033590104
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7815085158150852 0.7749391727493917
{'val': [0.7815085158150852], 'test': [0.7749391727493917]}
0
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
1
2
3
4
[6.13185334 6.13185334 6.13185334 6.13185334 6.13185334] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22506
evolution 1 cost time: 5.516666666666667 m
>> 3 of 3 finished 
fitness values of current population: 
0.21411 
0.21436 
0.21606 
>>> 2 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8980, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8740, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8537, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6989, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6680, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5201, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.6820695930057
cccccc
ddddddd
eeeeeee
0.7805352798053529 0.7805352798053529
{'val': [0.7805352798053529], 'test': [0.7805352798053529]}
0
1
2
3
4
[5.85310364 5.87029552 5.8446815  5.86330438 5.87320471] [0.19226209 0.20928588 0.18392231 0.20236309 0.21216662]
generate new algorithm using e1 with fitness value:  0.21946
evolution 1 cost time: 5.166666666666667 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(4.8723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1886, device='cuda:0', grad_fn=<NegBackward0>)
Error in API. 
tensor(3.9341, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7411, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6198, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5139, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4788, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4543, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.7527, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1751.1832383208805
cccccc
ddddddd
eeeeeee
0.7754257907542579 0.7851581508515816
{'val': [0.7754257907542579], 'test': [0.7851581508515816]}
0
1
2
3
4
[5.73299718 5.73299694 5.73299694 5.73299718 5.73299694] [0.20000014 0.1999999  0.1999999  0.20000014 0.1999999 ]
generate new algorithm using m1 with fitness value:  0.21484
evolution 1 cost time: 5.95 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9202052752178
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7822384428223844 0.7742092457420925
{'val': [0.7822384428223844], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.13254404 6.13254404 6.1325438  6.13254404 6.13254404] [0.20000005 0.20000005 0.19999981 0.20000005 0.20000005]
generate new algorithm using e1 with fitness value:  0.22579
evolution 1 cost time: 6.833333333333333 m
starting new request...
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3902, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2161, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1963, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9620, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.837943368488
cccccc
ddddddd
eeeeeee
0.7863746958637469 0.7936739659367397
{'val': [0.7863746958637469], 'test': [0.7936739659367397]}
0
1
2
3
4
[5.9117372  5.92277813 5.91889882 5.92721605 5.93090725] [0.18948153 0.20046833 0.19660804 0.2048845  0.2085576 ]
generate new algorithm using m1 with fitness value:  0.20633
evolution 1 cost time: 5.283333333333333 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
Error in API. 
4110
37
tensor(5.0668, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6799, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4953, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4294, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3792, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1715, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1025, device='cuda:0', grad_fn=<NegBackward0>)
tensor(0.0703, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 2030.2397692816126
cccccc
ddddddd
eeeeeee
Error in API. 
0.7824817518248175 0.780778588807786
{'val': [0.7824817518248175], 'test': [0.780778588807786]}
0
1
2
3
4
[5.89260697 5.88544583 5.88358855 5.88792229 5.8805654 ] [0.20659965 0.19941839 0.19755589 0.20190181 0.19452425]
generate new algorithm using e1 with fitness value:  0.21922
evolution 1 cost time: 7.666666666666667 m
starting new request...
NCI1
4110
37
Error: The shape of the mask [36] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: /home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)

All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 4918 is out of bounds for dimension 0 with size 4918
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The shape of the mask [232] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 4918 is out of bounds for dimension 0 with size 4918
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8517, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6943, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6688, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5359, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.3048494391971
cccccc
ddddddd
eeeeeee
0.7824817518248175 0.7824817518248175
{'val': [0.7824817518248175], 'test': [0.7824817518248175]}
0
1
2
3
4
[5.82826567 5.84594822 5.8199079  5.83925247 5.84853864] [0.19182506 0.20963402 0.18340756 0.20289041 0.21224295]
generate new algorithm using m1 with fitness value:  0.21752
evolution 1 cost time: 6.283333333333333 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.21411 
0.21436 
>>> 3 of 3 populations finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
NCI1
4110
37
Error: 'list' object has no attribute 'numpy'
warning! error code, retrying ... 
starting new request...
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error in API. 
Error: need at least one array to concatenate
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
NCI1
4110
37
Error: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * ()
 * (Tensor other)
 * (int dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
 * (name dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis

warning! error code, retrying ... 
starting new request...
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
tensor(4.8364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1886, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0910, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1966.7510592126184
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7871046228710463 0.7841849148418492
{'val': [0.7871046228710463], 'test': [0.7841849148418492]}
0
1
2
3
4
[5.88738251 5.89221978 5.8925643  5.88780403 5.89324141] [0.19674548 0.20157478 0.20191872 0.19716631 0.20259471]
generate new algorithm using e1 with fitness value:  0.21582
evolution 1 cost time: 12.616666666666667 m
starting new request...
NCI1
4110
37
tensor(4.8364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1886, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0908, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1966.750121479233
cccccc
ddddddd
eeeeeee
0.7883211678832117 0.7839416058394162
{'val': [0.7883211678832117], 'test': [0.7839416058394162]}
0
1
2
3
4
[5.88695121 5.89176893 5.89213252 5.88740897 5.8928144 ] [0.19674142 0.20155115 0.20191413 0.19719842 0.20259488]
generate new algorithm using m1 with fitness value:  0.21606
evolution 1 cost time: 4.9 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.920198414061
Error in API. 
cccccc
ddddddd
eeeeeee
Error in API. 
0.7824817518248175 0.7742092457420925
{'val': [0.7824817518248175], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.13254046 6.13254046 6.13254046 6.13254046 6.13254046] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22579
evolution 1 cost time: 5.283333333333333 m
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201742543114
cccccc
ddddddd
eeeeeee
0.7715328467153284 0.7768856447688564
{'val': [0.7715328467153284], 'test': [0.7768856447688564]}
0
1
2
3
4
[6.13254142 6.13254142 6.13254118 6.13254142 6.13254142] [0.20000005 0.20000005 0.19999981 0.20000005 0.20000005]
generate new algorithm using m1 with fitness value:  0.22311
evolution 1 cost time: 4.7 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: arrays used as indices must be of integer (or boolean) type
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: 'Tensor' object has no attribute 'copy'
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * ()
 * (Tensor other)
 * (int dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
 * (name dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis

warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.922963778178
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7815085158150852 0.7749391727493917
{'val': [0.7815085158150852], 'test': [0.7749391727493917]}
0
1
2
3
4
[6.13180542 6.13180542 6.13180542 6.13180542 6.13180542] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22506
evolution 1 cost time: 11.283333333333333 m
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.922978454166
cccccc
ddddddd
eeeeeee
0.7712895377128953 0.7746958637469586
{'val': [0.7712895377128953], 'test': [0.7746958637469586]}
0
1
2
3
4
[6.13180542 6.13180542 6.13180542 6.13180542 6.13180542] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.2253
evolution 1 cost time: 4.616666666666666 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.21411 
0.21436 
>>> 1 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9209326108296
cccccc
ddddddd
eeeeeee
0.7822384428223844 0.772992700729927
{'val': [0.7822384428223844], 'test': [0.772992700729927]}
0
1
2
3
4
[6.13112736 6.13112712 6.13112736 6.13112736 6.13112736] [0.20000005 0.19999981 0.20000005 0.20000005 0.20000005]
generate new algorithm using e1 with fitness value:  0.22701
evolution 1 cost time: 4.883333333333334 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9208974838257
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7710462287104622 0.7751824817518249
{'val': [0.7710462287104622], 'test': [0.7751824817518249]}
0
1
2
3
4
[6.13113523 6.13113523 6.13113523 6.13113546 6.13113523] [0.19999995 0.19999995 0.19999995 0.20000019 0.19999995]
generate new algorithm using m1 with fitness value:  0.22482
evolution 1 cost time: 5.183333333333334 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8736, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8528, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6885, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6715, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5225, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.2216777271694
cccccc
ddddddd
eeeeeee
Error in API. 
0.7798053527980535 0.7812652068126521
{'val': [0.7798053527980535], 'test': [0.7812652068126521]}
0
1
2
3
4
[5.84462762 5.86167955 5.83643413 5.85524583 5.86423993] [0.19212839 0.20929771 0.1838785  0.20281969 0.21187571]
generate new algorithm using e1 with fitness value:  0.21873
evolution 1 cost time: 5.75 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(5.2585, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7123, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3397, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2791, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2616, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0725, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0287, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.0572, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1989.782464770807
cccccc
ddddddd
eeeeeee
Error in API. 
0.7902676399026763 0.7851581508515816
{'val': [0.7902676399026763], 'test': [0.7851581508515816]}
0
1
2
3
4
[6.12529755 6.08803391 6.08377361 6.13668299 6.04983473] [0.22885611 0.19122324 0.18692073 0.24035437 0.15264555]
generate new algorithm using m1 with fitness value:  0.21484
evolution 1 cost time: 5.35 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: 'Tensor' object has no attribute 'pop'
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
Error in API. 
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8978, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8740, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8525, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6969, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6666, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5486, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.3755720323986
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7832116788321167 0.7834549878345499
{'val': [0.7832116788321167], 'test': [0.7834549878345499]}
0
1
2
3
4
[5.84881163 5.86495566 5.84015918 5.85823917 5.86663747] [0.19301793 0.20923881 0.18432429 0.20249035 0.21092862]
generate new algorithm using e1 with fitness value:  0.21655
evolution 1 cost time: 8.116666666666667 m
starting new request...
NCI1
4110
37
Error: index 2638 is out of bounds for dimension 0 with size 2638
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9202036062877
cccccc
ddddddd
eeeeeee
0.7822384428223844 0.7742092457420925
{'val': [0.7822384428223844], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.13254356 6.13254356 6.13254356 6.13254356 6.13254356] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22579
evolution 1 cost time: 4.95 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.21411 
0.21436 
>>> 2 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.7218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8187, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7789, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7880, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7287, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9060, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1821.5348090728123
cccccc
ddddddd
eeeeeee
0.7819951338199514 0.7878345498783454
{'val': [0.7819951338199514], 'test': [0.7878345498783454]}
0
1
2
3
4
[5.89678526 5.88551068 5.89313722 5.88556671 5.88653612] [0.20733826 0.19597043 0.20366004 0.19602692 0.19700435]
generate new algorithm using e1 with fitness value:  0.21217
evolution 1 cost time: 5.083333333333333 m
starting new request...
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: index 219 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: index 37 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error in API. 
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: /home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)

All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 219 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2861, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.702519774437
cccccc
ddddddd
eeeeeee
0.7705596107055962 0.783941605839416
{'val': [0.7705596107055962], 'test': [0.783941605839416]}
0
1
2
3
4
[5.23134232 5.25677276 5.24254227 5.24302864 5.22189474] [0.1922177  0.21767584 0.20342985 0.20391676 0.18275984]
generate new algorithm using m1 with fitness value:  0.21606
evolution 1 cost time: 8.266666666666667 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4221, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9229691558414
cccccc
ddddddd
eeeeeee
0.7807785888077858 0.7751824817518248
{'val': [0.7807785888077858], 'test': [0.7751824817518248]}
0
1
2
3
4
[6.13255119 6.13255119 6.13255119 6.13255119 6.13255119] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22482
evolution 1 cost time: 5.1 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9210544692146
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7824817518248175 0.772992700729927
{'val': [0.7824817518248175], 'test': [0.772992700729927]}
0
1
2
3
4
[6.13112402 6.13112402 6.13112402 6.13112402 6.13112402] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22701
evolution 1 cost time: 8.6 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.4368, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8207, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6369, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5404, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4219, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3617, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2406, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1996, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.7923, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1629.1232529083888
cccccc
ddddddd
eeeeeee
0.778345498783455 0.7866180048661799
{'val': [0.778345498783455], 'test': [0.7866180048661799]}
0
1
2
3
4
[5.81951666 5.81755662 5.82224703 5.8136549  5.8239851 ] [0.20012424 0.19816979 0.20284682 0.1942792  0.20457994]
generate new algorithm using e1 with fitness value:  0.21338
evolution 1 cost time: 5.033333333333333 m
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 13891 is out of bounds for dimension 0 with size 13891
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: 'numpy.ndarray' object has no attribute 'unsqueeze'
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 13891 is out of bounds for dimension 0 with size 13891
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.8091, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1236, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8242, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7634, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7454, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6844, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5375, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5407, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6485, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1764.1557154390548
cccccc
ddddddd
eeeeeee
0.7790754257907543 0.7793187347931874
{'val': [0.7790754257907543], 'test': [0.7793187347931874]}
0
1
2
3
4
[5.98902154 6.00572872 6.01748753 5.9950521  6.01288176] [0.18504552 0.20168781 0.21340095 0.19105266 0.20881307]
generate new algorithm using m1 with fitness value:  0.22068
evolution 1 cost time: 6.666666666666667 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.21217 
0.21338 
>>> 3 of 3 populations finished 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: eq() received an invalid combination of arguments - got (Tensor, numpy.ndarray), but expected one of:
 * (Tensor input, Tensor other, *, Tensor out)
 * (Tensor input, Number other, *, Tensor out)

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: can't assign a list to a torch.LongTensor
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: mat1 and mat2 shapes cannot be multiplied (15191x34 and 37x32)
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: 'Tensor' object has no attribute 'isin'
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: eq() received an invalid combination of arguments - got (Tensor, numpy.ndarray), but expected one of:
 * (Tensor input, Tensor other, *, Tensor out)
 * (Tensor input, Number other, *, Tensor out)

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: tensors used as indices must be long, int, byte or bool tensors
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: any() received an invalid combination of arguments - got (bool, dim=int), but expected one of:
 * (Tensor input, *, Tensor out)
 * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)
 * (Tensor input, int dim, bool keepdim, *, Tensor out)
 * (Tensor input, name dim, bool keepdim, *, Tensor out)

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: tensor(0)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 13891 is out of bounds for dimension 0 with size 13891
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-2, 1], but got 2)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: /home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)

All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: list index out of range
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.6079, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0361, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8375, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7787, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7029, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6212, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5234, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4860, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.7568, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1739.2675829198624
cccccc
ddddddd
eeeeeee
Error in API. 
0.7688564476885645 0.7766423357664235
{'val': [0.7688564476885645], 'test': [0.7766423357664235]}
0
1
2
3
4
[5.85281897 5.87156653 5.85814905 5.86230588 5.85782385] [0.19222155 0.21112602 0.19759625 0.20178786 0.19726832]
generate new algorithm using e1 with fitness value:  0.22336
evolution 1 cost time: 18.716666666666665 m
starting new request...
NCI1
4110
37
Error: The shape of the mask [2] at index 0 does not match the shape of the indexed tensor [116, 2] at index 0
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: 16790
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.920174439748
cccccc
ddddddd
eeeeeee
0.7751824817518248 0.7756690997566911
{'val': [0.7751824817518248], 'test': [0.7756690997566911]}
0
1
2
3
4
[6.13254786 6.13254786 6.13254786 6.13254786 6.13254786] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22433
evolution 1 cost time: 5.95 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: 
All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The shape of the mask [37] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: tensors used as indices must be long, int, byte or bool tensors
warning! error code, retrying ... 
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The shape of the mask [37] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x', 'edge_index', 'y'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning
  warnings.warn(
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: can't assign a numpy.ndarray to a torch.LongTensor
warning! error code, retrying ... 
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
Error: 26
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The expanded size of the tensor (116) must match the existing size (98) at non-singleton dimension 0.  Target sizes: [116].  Tensor sizes: [98]
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 0 is out of bounds for axis 0 with size 0
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: 'list' object has no attribute 'numpy'
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: tensor(0)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: mat1 and mat2 shapes cannot be multiplied (1488x30 and 37x32)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6676, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4229, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.910105334388
cccccc
ddddddd
eeeeeee
0.7688564476885645 0.7790754257907542
{'val': [0.7688564476885645], 'test': [0.7790754257907542]}
0
1
2
3
4
[6.13374019 6.13374019 6.13374019 6.13374043 6.13374066] [0.19999986 0.19999986 0.19999986 0.2000001  0.20000033]
generate new algorithm using e1 with fitness value:  0.22092
evolution 1 cost time: 8.283333333333333 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
Error: sum() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * (*, torch.dtype dtype)
      didn't match because some of the keywords were incorrect: out, axis
 * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)
 * (tuple of names dim, bool keepdim, *, torch.dtype dtype)

warning! error code, retrying ... 
starting new request...
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
Error: tensor(0)
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error: invalid syntax (ael_alg.py, line 8)
warning! error code, retrying ... 
starting new request...
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: can't assign a numpy.ndarray to a torch.LongTensor
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: drop_nodes() missing 1 required positional argument: 'drop_probability'
warning! error code, retrying ... 
starting new request...
Error: invalid syntax (ael_alg.py, line 8)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
Error in API. 
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201880031162
cccccc
ddddddd
eeeeeee
Error in API. 
0.7686131386861313 0.7771289537712895
{'val': [0.7686131386861313], 'test': [0.7771289537712895]}
0
1
2
3
4
[6.13254666 6.13254666 6.13254642 6.13254666 6.13254666] [0.20000005 0.20000005 0.19999981 0.20000005 0.20000005]
generate new algorithm using m1 with fitness value:  0.22287
evolution 1 cost time: 11.583333333333334 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: can't assign a numpy.ndarray to a torch.LongTensor
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: tensor(0)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 10862 is out of bounds for dimension 0 with size 10862
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 13891 is out of bounds for dimension 0 with size 13891
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)
warning! error code, retrying ... 
starting new request...
Error: closing parenthesis ')' does not match opening parenthesis '[' (ael_alg.py, line 15)
warning! error code, retrying ... 
starting new request...
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7148, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2768, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1923, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0335, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9010, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
tensor(3.7398, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.1961, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1849.7448350356685
cccccc
ddddddd
eeeeeee
0.767396593673966 0.7766423357664234
{'val': [0.767396593673966], 'test': [0.7766423357664234]}
0
1
2
3
4
[5.93029642 5.91719484 5.92010927 5.92324233 5.93000674] [0.20611353 0.19303969 0.19594795 0.19907437 0.20582446]
generate new algorithm using e1 with fitness value:  0.22336
evolution 1 cost time: 7.183333333333334 m
starting new request...
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.7218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8186, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7784, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7872, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7274, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9044, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1821.3858384291332
cccccc
ddddddd
eeeeeee
0.7922141119221411 0.7927007299270074
{'val': [0.7922141119221411], 'test': [0.7927007299270074]}
0
1
2
3
4
[5.87501431 5.86359    5.8754487  5.86442351 5.86384082] [0.2065856  0.19510067 0.20702231 0.1959386  0.19535282]
generate new algorithm using m1 with fitness value:  0.2073
evolution 1 cost time: 5.5 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.2073 
0.21217 
>>> 1 of 3 populations finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8639, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.7126845651203
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7717761557177616 0.7854014598540147
{'val': [0.7717761557177616], 'test': [0.7854014598540147]}
0
1
2
3
4
[5.23072577 5.25647092 5.24224854 5.24215412 5.22167969] [0.19205329 0.21785256 0.20360028 0.20350567 0.1829882 ]
generate new algorithm using e1 with fitness value:  0.2146
evolution 1 cost time: 6.566666666666666 m
starting new request...
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
Error: index 37 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4748, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3539, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2852, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8645, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.6068833271663
cccccc
ddddddd
eeeeeee
0.7727493917274939 0.783698296836983
{'val': [0.7727493917274939], 'test': [0.783698296836983]}
0
1
2
3
4
[5.21803188 5.24399996 5.22971392 5.23055625 5.20976639] [0.19159848 0.21762766 0.203308   0.20415232 0.18331354]
generate new algorithm using m1 with fitness value:  0.2163
evolution 1 cost time: 6.05 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.7218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8186, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7787, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7864, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8992, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1821.3282302618027
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.783698296836983 0.791970802919708
{'val': [0.783698296836983], 'test': [0.791970802919708]}
0
1
2
3
4
[5.88369226 5.87105894 5.8810761  5.8712914  5.87213635] [0.20790149 0.19517112 0.20526522 0.19540536 0.19625681]
generate new algorithm using e1 with fitness value:  0.20803
evolution 1 cost time: 7.116666666666666 m
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9577, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.64682050546
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7846715328467153 0.786374695863747
{'val': [0.7846715328467153], 'test': [0.786374695863747]}
0
1
2
3
4
[5.9114511  5.92340875 5.91976094 5.92944407 5.93117762] [0.1885023  0.20035715 0.19674071 0.2063406  0.20805924]
generate new algorithm using m1 with fitness value:  0.21363
evolution 1 cost time: 7.633333333333334 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2161, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1964, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9587, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.8216644128163
cccccc
ddddddd
eeeeeee
Error in API. 
0.7856447688564476 0.7914841849148418
{'val': [0.7856447688564476], 'test': [0.7914841849148418]}
0
1
2
3
4
[5.90146542 5.91281343 5.90937018 5.91756082 5.92103791] [0.18908126 0.20036171 0.19693897 0.20508083 0.20853723]
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
generate new algorithm using e1 with fitness value:  0.20852
evolution 1 cost time: 7.0 m
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * ()
 * (Tensor other)
 * (int dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
 * (name dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8735, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8517, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6941, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6689, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5331, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.3061814573075
cccccc
ddddddd
eeeeeee
0.7824817518248175 0.7802919708029197
{'val': [0.7824817518248175], 'test': [0.7802919708029197]}
0
1
2
3
4
[5.82646751 5.84431434 5.81828308 5.83730745 5.8466475 ] [0.1918059  0.20977915 0.18356348 0.20272263 0.21212884]
generate new algorithm using m1 with fitness value:  0.21971
evolution 1 cost time: 6.0 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.2073 
0.20803 
>>> 2 of 3 populations finished 
starting new request...
NCI1
4110
37
Error: index 219 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4747, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3538, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2851, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8601, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.6012096537484
cccccc
ddddddd
eeeeeee
Error in API. 
0.769829683698297 0.786131386861314
{'val': [0.769829683698297], 'test': [0.786131386861314]}
0
1
2
3
4
[5.20168591 5.22912693 5.2146399  5.21493936 5.19446898] [0.19067519 0.21822998 0.20368289 0.20398359 0.18342834]
generate new algorithm using e1 with fitness value:  0.21387
evolution 1 cost time: 5.683333333333334 m
starting new request...
NCI1
4110
37
Error: index 74 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error in API. 
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201841089462
cccccc
ddddddd
eeeeeee
0.780778588807786 0.7717761557177616
{'val': [0.780778588807786], 'test': [0.7717761557177616]}
0
1
2
3
4
[6.13254642 6.13254642 6.13254642 6.13254642 6.13254642] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22822
evolution 1 cost time: 6.05 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.6908, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1064, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9020, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8464, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7427, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6196, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5919, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6095, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1793.2157721784379
cccccc
ddddddd
eeeeeee
Error in API. 
0.7832116788321167 0.7895377128953771
{'val': [0.7832116788321167], 'test': [0.7895377128953771]}
0
1
2
3
4
[5.88299322 5.9010458  5.87229395 5.89143014 5.89415908] [0.19465461 0.21255374 0.18404628 0.20301981 0.20572556]
generate new algorithm using e1 with fitness value:  0.21046
evolution 1 cost time: 5.966666666666667 m
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3901, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2162, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9572, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.8660629325443
cccccc
ddddddd
eeeeeee
0.7790754257907543 0.7912408759124088
{'val': [0.7790754257907543], 'test': [0.7912408759124088]}
0
1
2
3
4
[5.90689445 5.91761255 5.91459942 5.92243767 5.926229  ] [0.18939249 0.20005765 0.1970594  0.20485893 0.20863153]
generate new algorithm using m1 with fitness value:  0.20876
evolution 1 cost time: 5.433333333333334 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
NCI1
4110
37
Error: 15589
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: 'list' object has no attribute 'numpy'
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9579, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.6466087500255
cccccc
ddddddd
eeeeeee
Error in API. 
0.783941605839416 0.7858880778588808
{'val': [0.783941605839416], 'test': [0.7858880778588808]}
0
1
2
3
4
[5.91087699 5.92285514 5.91918707 5.9288528  5.93067479] [0.18848627 0.20036267 0.19672576 0.20630938 0.2081159 ]
generate new algorithm using e1 with fitness value:  0.21411
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
evolution 1 cost time: 8.916666666666666 m
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0000, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8980, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8738, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8535, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6976, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6663, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5326, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1806.4800669219758
cccccc
ddddddd
eeeeeee
0.7815085158150852 0.7802919708029197
{'val': [0.7815085158150852], 'test': [0.7802919708029197]}
0
1
2
3
4
[5.85657787 5.87344003 5.84789109 5.86663342 5.8763411 ] [0.19234392 0.20933312 0.18359168 0.20247522 0.21225606]
generate new algorithm using m1 with fitness value:  0.21971
evolution 1 cost time: 5.333333333333333 m
>> 3 of 3 finished 
fitness values of current population: 
0.20633 
0.2073 
0.20803 
>>> 3 of 3 populations finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.6908, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1064, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9020, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8464, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7427, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6196, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5921, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6131, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1793.2207235627704
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
Error in API. 
0.7812652068126521 0.7895377128953772
{'val': [0.7812652068126521], 'test': [0.7895377128953772]}
0
1
2
3
4
[5.87423038 5.89226198 5.86364031 5.88219833 5.88560414] [0.19468681 0.21257212 0.18418265 0.20259012 0.2059683 ]
generate new algorithm using e1 with fitness value:  0.21046
evolution 1 cost time: 5.533333333333333 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
Error: index 39 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8186, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7786, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7864, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8987, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1821.324008014467
cccccc
ddddddd
eeeeeee
Error in API. 
0.7824817518248175 0.78661800486618
{'val': [0.7824817518248175], 'test': [0.78661800486618]}
0
1
2
3
4
[5.89042473 5.87781405 5.8880837  5.87798071 5.87871337] [0.20788116 0.19517416 0.20552225 0.19534209 0.19608035]
generate new algorithm using m1 with fitness value:  0.21338
evolution 1 cost time: 5.666666666666667 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
Error: index 172 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: The shape of the mask [2, 116] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 47 is out of bounds for dimension 0 with size 47
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.6883, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1469, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0161, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9327, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8808, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8137, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7812, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7081, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6307, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1817.6332698265712
cccccc
ddddddd
eeeeeee
0.7936739659367398 0.78661800486618
{'val': [0.7936739659367398], 'test': [0.78661800486618]}
0
1
2
3
4
[5.86369681 5.85353613 5.86965752 5.870821   5.86522889] [0.19910014 0.1888414  0.20511837 0.20629308 0.20064701]
generate new algorithm using e1 with fitness value:  0.21338
evolution 1 cost time: 5.55 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.6296, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1109, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0633, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9806, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9574, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8490, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7264, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6716, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5330, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1818.9863600201077
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7871046228710462 0.7956204379562044
{'val': [0.7871046228710462], 'test': [0.7956204379562044]}
0
1
2
3
4
[5.79993033 5.7916584  5.80785227 5.80556488 5.79258776] [0.20041209 0.19213036 0.20834341 0.20605331 0.19306082]
generate new algorithm using m1 with fitness value:  0.20438
evolution 1 cost time: 8.7 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2861, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.7024791770511
cccccc
ddddddd
eeeeeee
0.7708029197080292 0.783941605839416
{'val': [0.7708029197080292], 'test': [0.783941605839416]}
0
1
2
3
4
[5.23133993 5.25677013 5.24253988 5.24302626 5.2218926 ] [0.1922177  0.21767561 0.20342985 0.20391676 0.18276008]
generate new algorithm using e1 with fitness value:  0.21606
evolution 1 cost time: 5.8 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: 'list' object has no attribute 'numpy'
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: '>' not supported between instances of 'Tensor' and 'numpy.ndarray'
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
duplicated code, wait 1 second and retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error in API. 
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4748, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3539, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2852, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8647, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.6032998164494
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7727493917274939 0.7839416058394161
{'val': [0.7727493917274939], 'test': [0.7839416058394161]}
0
1
2
3
4
[5.21864605 5.24445415 5.23021531 5.23104095 5.21021128] [0.19171514 0.21757744 0.2033087  0.20413608 0.18326265]
duplicated result, retrying ... 
generate new algorithm using m1 with fitness value:  0.21606
evolution 1 cost time: 10.183333333333334 m
>> 3 of 3 finished 
fitness values of current population: 
0.20438 
0.20633 
0.2073 
>>> 1 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2861, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.7023874521255
Error in API. 
cccccc
ddddddd
eeeeeee
0.7705596107055962 0.783941605839416
{'val': [0.7705596107055962], 'test': [0.783941605839416]}
0
1
2
3
4
[5.23187566 5.25728369 5.24305201 5.24355125 5.22242951] [0.19222876 0.21766453 0.20341731 0.2039171  0.1827723 ]
generate new algorithm using e1 with fitness value:  0.21606
evolution 1 cost time: 5.5 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
Error in API. 
cccccc
ddddddd
eeeeeee
Error: 
All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
tensor(4.6948, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9138, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6930, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5112, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3427, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2354, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2109, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.7721, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1659.221789267328
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7846715328467153 0.7800486618004866
{'val': [0.7846715328467153], 'test': [0.7800486618004866]}
0
1
2
3
4
[5.60192966 5.60418224 5.59328246 5.59255481 5.60292029] [0.20294685 0.20519263 0.19432574 0.19360028 0.20393449]
generate new algorithm using m1 with fitness value:  0.21995
evolution 1 cost time: 7.05 m
>> 1 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
Error in API. 
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2861, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.702503124873
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7710462287104622 0.7836982968369829
{'val': [0.7710462287104622], 'test': [0.7836982968369829]}
0
1
2
3
4
[5.23121428 5.25662899 5.24239564 5.24288321 5.22173071] [0.19223559 0.21767692 0.20342866 0.20391674 0.18274208]
generate new algorithm using e1 with fitness value:  0.2163
evolution 1 cost time: 6.35 m
starting new request...
NCI1
4110
37
tensor(4.9667, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2543, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8965, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7595, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6213, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5808, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4771, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4088, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.5198, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Epoch 1, Loss 1760.762533320321
cccccc
ddddddd
eeeeeee
0.7788321167883212 0.7851581508515815
{'val': [0.7788321167883212], 'test': [0.7851581508515815]}
0
1
2
3
4
[5.62286806 5.61584902 5.6233325  5.62083387 5.62049413] [0.20218072 0.19519954 0.20264265 0.2001575  0.19981959]
generate new algorithm using m1 with fitness value:  0.21484
evolution 1 cost time: 4.766666666666667 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
tensor(4.7679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6743, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4746, device='cuda:0', grad_fn=<NegBackward0>)
Error in API. 
tensor(3.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2861, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1704.7024793624878
cccccc
ddddddd
eeeeeee
0.7705596107055962 0.783941605839416
{'val': [0.7705596107055962], 'test': [0.783941605839416]}
0
1
2
3
4
[5.23134089 5.25677109 5.24254107 5.24302721 5.22189355] [0.19221766 0.21767555 0.20343004 0.20391671 0.18276003]
generate new algorithm using e1 with fitness value:  0.21606
evolution 1 cost time: 6.733333333333333 m
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: 
All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: The shape of the mask [2, 190] at index 0 does not match the shape of the indexed tensor [2, 190] at index 1
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error in API. 
Error: The shape of the mask [232] at index 0 does not match the shape of the indexed tensor [2, 116] at index 0
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: too many values to unpack (expected 2)
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 72 is out of bounds for dimension 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7732, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0544, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8341, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7049, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5619, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4648, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2807, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2418, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6958, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1700.7884209420945
Error in API. 
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7737226277372262 0.7851581508515816
{'val': [0.7737226277372262], 'test': [0.7851581508515816]}
0
1
2
3
4
[5.42936516 5.42608285 5.42144489 5.41427898 5.41848755] [0.20742919 0.20414868 0.19951327 0.1923513  0.19655755]
generate new algorithm using m1 with fitness value:  0.21484
evolution 1 cost time: 10.616666666666667 m
>> 3 of 3 finished 
fitness values of current population: 
0.20438 
0.20633 
0.2073 
>>> 2 of 3 populations finished 
starting new request...
NCI1
4110
37
Error: index 219 is out of bounds for axis 0 with size 37
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: /home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)

All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.7218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8187, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7789, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7880, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7287, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9060, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1821.534873896175
cccccc
ddddddd
eeeeeee
0.7822384428223845 0.7883211678832116
{'val': [0.7822384428223845], 'test': [0.7883211678832116]}
0
1
2
3
4
[5.89693427 5.8856585  5.89330673 5.88569403 5.88667583] [0.20734068 0.19597155 0.20368311 0.19600736 0.1969973 ]
generate new algorithm using e1 with fitness value:  0.21168
evolution 1 cost time: 5.816666666666666 m
starting new request...
NCI1
4110
37
tensor(4.7313, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3441, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0896, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9873, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0196, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8586, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8377, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8296, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6027, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1859.2059396372902
cccccc
ddddddd
eeeeeee
Error in API. 
0.7900243309002434 0.7961070559610705
{'val': [0.7900243309002434], 'test': [0.7961070559610705]}
0
1
2
3
4
[5.72093821 5.71724558 5.72052574 5.71367311 5.72683382] [0.20109716 0.19739695 0.20068385 0.19381714 0.20700489]
generate new algorithm using m1 with fitness value:  0.20389
evolution 1 cost time: 5.016666666666667 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4217, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9198484420776
cccccc
ddddddd
eeeeeee
0.7722627737226277 0.7773722627737226
{'val': [0.7722627737226277], 'test': [0.7773722627737226]}
0
1
2
3
4
[6.13217354 6.13217354 6.13217354 6.13217354 6.13217354] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22263
evolution 1 cost time: 4.466666666666667 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error: any() received an invalid combination of arguments - got (bool, dim=int), but expected one of:
 * (Tensor input, *, Tensor out)
 * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)
 * (Tensor input, int dim, bool keepdim, *, Tensor out)
 * (Tensor input, name dim, bool keepdim, *, Tensor out)

warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: any() received an invalid combination of arguments - got (bool, dim=int), but expected one of:
 * (Tensor input, *, Tensor out)
 * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)
 * (Tensor input, int dim, bool keepdim, *, Tensor out)
 * (Tensor input, name dim, bool keepdim, *, Tensor out)

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: t() expects a tensor with <= 2 dimensions, but self is 3D
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201803737217
cccccc
ddddddd
eeeeeee
Error in API. 
0.7824817518248175 0.7744525547445256
{'val': [0.7824817518248175], 'test': [0.7744525547445256]}
0
1
2
3
4
[6.13254547 6.13254547 6.13254547 6.13254547 6.13254547] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22555
evolution 1 cost time: 8.3 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.5092, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8296, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6560, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4603, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2766, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1738, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9676, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1614.1553907791774
cccccc
ddddddd
eeeeeee
0.7922141119221411 /home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
0.7892944038929441
{'val': [0.7922141119221411], 'test': [0.7892944038929441]}
0
1
2
3
4
[5.7757504  5.79179668 5.78491974 5.78964257 5.79510307] [0.18828428 0.20436299 0.19747215 0.20220452 0.20767606]
generate new algorithm using e1 with fitness value:  0.21071
evolution 1 cost time: 4.866666666666666 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.5092, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8296, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6560, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4603, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2764, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1734, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1081, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9666, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1614.103027926551
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
Error in API. 
0.7939172749391729 0.7851581508515816
{'val': [0.7939172749391729], 'test': [0.7851581508515816]}
0
1
2
3
4
[5.78151703 5.7973609  5.79082322 5.79544353 5.80132365] [0.18833265 0.20402949 0.19755248 0.20212992 0.20795547]
generate new algorithm using m1 with fitness value:  0.21484
evolution 1 cost time: 5.366666666666666 m
>> 3 of 3 finished 
fitness values of current population: 
0.20389 
0.20438 
0.20633 
>>> 3 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
tensor(nan, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss nan
cccccc
ddddddd
eeeeeee
Error: 
All the 35 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
35 fits failed with the following error:
Traceback (most recent call last):
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/svm/_base.py", line 192, in fit
    X, y = self._validate_data(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 1106, in check_X_y
    X = check_array(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
Error in API. 
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201863341862
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7824817518248175 0.7742092457420925
{'val': [0.7824817518248175], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.13254738 6.13254738 6.13254738 6.13254738 6.13254738] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22579
evolution 1 cost time: 11.016666666666667 m
starting new request...
NCI1
4110
37
tensor(4.1729, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3834, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1361, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9951, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8241, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6666, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5760, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5210, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.6332, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1378.4543527232277
cccccc
ddddddd
eeeeeee
0.7793187347931874 0.7832116788321167
{'val': [0.7793187347931874], 'test': [0.7832116788321167]}
0
1
2
3
4
[6.13080621 6.13080621 6.13080621 6.13080621 6.13080621] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.21679
evolution 1 cost time: 5.5 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4221, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.922981368171
cccccc
ddddddd
eeeeeee
Error in API. 
0.7810218978102189 0.7751824817518248
{'val': [0.7810218978102189], 'test': [0.7751824817518248]}
0
1
2
3
4
[6.13250828 6.13250804 6.13250804 6.13250804 6.13250828] [0.20000014 0.1999999  0.1999999  0.1999999  0.20000014]
generate new algorithm using e1 with fitness value:  0.22482
evolution 1 cost time: 4.45 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
duplicated code, wait 1 second and retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9229656060536
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7815085158150852 0.7746958637469585
{'val': [0.7815085158150852], 'test': [0.7746958637469585]}
0
1
2
3
4
[6.13181186 6.13181186 6.13181186 6.13181186 6.13181186] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.2253
evolution 1 cost time: 8.416666666666666 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3897, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2146, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1947, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9578, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.6460851298439
cccccc
ddddddd
eeeeeee
0.7841849148418492 0.7878345498783454
{'val': [0.7841849148418492], 'test': [0.7878345498783454]}
0
1
2
3
4
[5.91078448 5.92278671 5.91915584 5.9288063  5.93065023] [0.18844709 0.20034702 0.19674709 0.2063153  0.20814351]
generate new algorithm using e1 with fitness value:  0.21217
evolution 1 cost time: 4.766666666666667 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error: algorithm or code not identified, wait 1 seconds and retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
Error in API. 
NCI1
4110
37
Error: index 10862 is out of bounds for dimension 0 with size 10862
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error in API. 
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: 16
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 13891 is out of bounds for dimension 0 with size 13891
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: Cannot take a larger sample than population when 'replace=False'
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 10862 is out of bounds for dimension 0 with size 10862
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only one element tensors can be converted to Python scalars
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: any() received an invalid combination of arguments - got (bool, dim=int), but expected one of:
 * (Tensor input, *, Tensor out)
 * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)
 * (Tensor input, int dim, bool keepdim, *, Tensor out)
 * (Tensor input, name dim, bool keepdim, *, Tensor out)

warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5230, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4223, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9070274564956
cccccc
ddddddd
eeeeeee
0.7817518248175183 0.7737226277372262
{'val': [0.7817518248175183], 'test': [0.7737226277372262]}
0
1
2
3
4
[6.13408732 6.13408732 6.13408732 6.13408732 6.13408732] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22628
evolution 1 cost time: 8.433333333333334 m
>> 3 of 3 finished 
fitness values of current population: 
0.20389 
0.20438 
0.20633 
>>> 1 of 3 populations finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
NCI1
4110
37
tensor(4.4445, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8417, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6402, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5388, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4649, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4028, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2597, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
tensor(3.2291, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8104, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1638.3650537464355
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7766423357664234 0.7851581508515816
{'val': [0.7766423357664234], 'test': [0.7851581508515816]}
0
1
2
3
4
[5.86111212 5.86145401 5.8594811  5.8579886  5.87026167] [0.19905735 0.19939753 0.19743446 0.1959494  0.20816126]
generate new algorithm using e1 with fitness value:  0.21484
evolution 1 cost time: 6.833333333333333 m
starting new request...
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9201842943828
cccccc
ddddddd
eeeeeee
0.7824817518248175 0.7742092457420925
{'val': [0.7824817518248175], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.1325469  6.13254714 6.13254714 6.13254714 6.13254714] [0.19999981 0.20000005 0.20000005 0.20000005 0.20000005]
generate new algorithm using m1 with fitness value:  0.22579
evolution 1 cost time: 4.916666666666667 m
>> 1 of 3 finished 
starting new request...
duplicated code, wait 1 second and retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1933, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4432, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1465, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9838, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8903, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.7768, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6695, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5846, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.2737, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1402.4851984447903
cccccc
ddddddd
eeeeeee
Error in API. 
0.769829683698297 0.7773722627737226
{'val': [0.769829683698297], 'test': [0.7773722627737226]}
0
1
2
3
4
[6.05639696 6.05704856 6.06004095 6.05745983 6.05847979] [0.19850926 0.19916194 0.20215934 0.1995739  0.20059556]
generate new algorithm using e1 with fitness value:  0.22263
evolution 1 cost time: 4.333333333333333 m
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.4502, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8712, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6446, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5450, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4725, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3181, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2672, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2412, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.0385, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1637.3586016231113
cccccc
ddddddd
eeeeeee
0.7822384428223845 0.7900243309002433
{'val': [0.7822384428223845], 'test': [0.7900243309002433]}
0
1
2
3
4
[6.02351308 6.02002716 6.02215195 6.0175724  6.01840734] [0.20318201 0.19969245 0.20181946 0.19723514 0.19807095]
generate new algorithm using m1 with fitness value:  0.20998
evolution 1 cost time: 4.983333333333333 m
>> 2 of 3 finished 
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.3984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8034, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4455, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3896, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2147, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1946, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9592, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1626.6281285021041
cccccc
ddddddd
eeeeeee
0.783698296836983 0.7871046228710463
{'val': [0.783698296836983], 'test': [0.7871046228710463]}
0
1
2
3
4
[5.90720367 5.9191277  5.91529894 5.92512822 5.92665005] [0.18862179 0.20044211 0.19664665 0.20639043 0.20789902]
generate new algorithm using e1 with fitness value:  0.2129
evolution 1 cost time: 4.966666666666667 m
starting new request...
NCI1
4110
37
Error: index 12344 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
Error: index 12345 is out of bounds for dimension 0 with size 12344
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6105, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4237, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.8920505841572
cccccc
ddddddd
eeeeeee
0.7822384428223844 0.7729927007299271
{'val': [0.7822384428223844], 'test': [0.7729927007299271]}
0
1
2
3
4
[6.13210058 6.13210058 6.13210058 6.13210058 6.13210058] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22701
evolution 1 cost time: 5.15 m
>> 3 of 3 finished 
fitness values of current population: 
0.20389 
0.20438 
0.20633 
>>> 2 of 3 populations finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.4786, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8763, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7672, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6637, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5797, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5132, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3553, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3470, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8263, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1681.5457656118606
cccccc
ddddddd
eeeeeee
Error in API. 
Error in API. 
0.7815085158150852 0.7924574209245743
{'val': [0.7815085158150852], 'test': [0.7924574209245743]}
0
1
2
3
4
[6.126719   6.14864969 6.14192414 6.15510559 6.14947748] [0.18233627 0.20427634 0.19754791 0.210735   0.20510448]
generate new algorithm using e1 with fitness value:  0.20754
evolution 1 cost time: 5.966666666666667 m
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6676, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4229, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.91015958786
cccccc
ddddddd
eeeeeee
0.7824817518248175 0.7744525547445256
{'val': [0.7824817518248175], 'test': [0.7744525547445256]}
0
1
2
3
4
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
[6.13373995 6.13373971 6.13373995 6.13373995 6.13373995] [0.20000005 0.19999981 0.20000005 0.20000005 0.20000005]
generate new algorithm using m1 with fitness value:  0.22555
evolution 1 cost time: 4.55 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4221, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9228916433121
cccccc
ddddddd
eeeeeee
0.7807785888077858 0.7751824817518248
{'val': [0.7807785888077858], 'test': [0.7751824817518248]}
0
1
2
3
4
[6.13248682 6.13248682 6.13248682 6.13248682 6.13248706] [0.19999995 0.19999995 0.19999995 0.19999995 0.20000019]
generate new algorithm using e1 with fitness value:  0.22482
evolution 1 cost time: 4.583333333333333 m
starting new request...
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.9767, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6248, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4411, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3472, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2895, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2507, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1913, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1294, device='cuda:0', grad_fn=<NegBackward0>)
tensor(0.3203, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 2005.8761118120617
cccccc
ddddddd
eeeeeee
Error in API. 
0.7763990267639902 0.791970802919708
{'val': [0.7763990267639902], 'test': [0.791970802919708]}
0
1
2
3
4
[5.79969311 5.80727625 5.79513431 5.79480124 5.79310632] [0.2016795  0.20921167 0.19715134 0.19682051 0.19513698]
generate new algorithm using m1 with fitness value:  0.20803
evolution 1 cost time: 7.266666666666667 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
Error in API. 
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.923046429952
cccccc
ddddddd
eeeeeee
Error in API. 
0.7659367396593673 0.7744525547445256
{'val': [0.7659367396593673], 'test': [0.7744525547445256]}
0
Error in API. 
1
2
3
4
[6.13181281 6.13181281 6.13181281 6.13181281 6.13181281] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22555
evolution 1 cost time: 9.866666666666667 m
starting new request...
NCI1
4110
37
tensor(4.1901, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4516, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1214, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9525, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8249, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6924, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6226, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5443, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.2997, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1386.0522680282593
cccccc
ddddddd
eeeeeee
0.7717761557177616 0.7846715328467154
{'val': [0.7717761557177616], 'test': [0.7846715328467154]}
0
1
2
3
4
[6.2041719  6.20417166 6.2041719  6.20417166 6.20417166] [0.20000014 0.1999999  0.20000014 0.1999999  0.1999999 ]
generate new algorithm using m1 with fitness value:  0.21533
evolution 1 cost time: 4.4 m
>> 3 of 3 finished 
fitness values of current population: 
0.20389 
0.20438 
0.20633 
>>> 3 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4228, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9229764143627
cccccc
ddddddd
eeeeeee
0.7639902676399026 0.7742092457420925
{'val': [0.7639902676399026], 'test': [0.7742092457420925]}
0
1
2
3
4
[6.13180637 6.13180637 6.13180637 6.13180637 6.13180637] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using e1 with fitness value:  0.22579
evolution 1 cost time: 4.166666666666667 m
starting new request...
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
Error: The shape of the mask [232] at index 0 does not match the shape of the indexed tensor [2, 116] at index 1
warning! error code, retrying ... 
starting new request...
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4218, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Epoch 1, Loss 1379.9201991558075
cccccc
ddddddd
eeeeeee
0.7652068126520681 0.772992700729927
{'val': [0.7652068126520681], 'test': [0.772992700729927]}
0
1
2
3
4
[6.13254166 6.13254166 6.13254166 6.13254166 6.13254166] [0.2 0.2 0.2 0.2 0.2]
generate new algorithm using m1 with fitness value:  0.22701
evolution 1 cost time: 8.216666666666667 m
>> 1 of 3 finished 
starting new request...
Error in API. 
NCI1
4110
37
tensor(4.6084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1375, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0339, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8584, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7836, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6791, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7413, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.9087, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1805.8837492863338
cccccc
ddddddd
eeeeeee
Error in API. 
0.778345498783455 0.791970802919708
{'val': [0.778345498783455], 'test': [0.791970802919708]}
0
1
2
3
4
[5.9239943  5.93039584 5.92243767 5.93151808 5.92775059] [0.1967789  0.20317272 0.19522414 0.2042936  0.20053065]
generate new algorithm using e1 with fitness value:  0.20803
evolution 1 cost time: 4.65 m
starting new request...
NCI1
4110
37
Error: only integer tensors of a single element can be converted to an index
warning! error code, retrying ... 
starting new request...
NCI1
4110
37
tensor(4.4154, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8225, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6647, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4867, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4465, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3752, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3102, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2217, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8387, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1633.8426763084199
cccccc
ddddddd
eeeeeee
0.778102189781022 0.7895377128953772
{'val': [0.778102189781022], 'test': [0.7895377128953772]}
0
1
2
3
4
[6.00744677 6.00663042 6.00396752 6.00984526 6.00722647] [0.20042323 0.19960736 0.19694602 0.20282032 0.20020306]
generate new algorithm using m1 with fitness value:  0.21046
evolution 1 cost time: 4.533333333333333 m
>> 2 of 3 finished 
starting new request...
starting new request...
killed current thread
NCI1
4110
37
tensor(4.5181, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8771, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6390, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5718, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5114, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3689, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2650, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1998, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.6217, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1646.022638493114
cccccc
ddddddd
eeeeeee
Error in API. 
0.7861313868613139 0.7924574209245743
{'val': [0.7861313868613139], 'test': [0.7924574209245743]}
0
1
2
3
4
[5.85750604 5.85158205 5.85934043 5.8558557  5.85711741] [0.20122071 0.19532089 0.20304762 0.19957711 0.20083367]
generate new algorithm using e1 with fitness value:  0.20754
evolution 1 cost time: 4.7 m
starting new request...
NCI1
4110
37
tensor(4.7903, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1926, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0714, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9586, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8626, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6558, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6378, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.3320, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1816.5964363349808
cccccc
ddddddd
eeeeeee
0.7798053527980535 0.7805352798053528
{'val': [0.7798053527980535], 'test': [0.7805352798053528]}
0
1
2
3
4
[5.55634975 5.54315853 5.57238317 5.56049991 5.5678606 ] [0.19627377 0.18299133 0.21241806 0.20045262 0.20786422]
generate new algorithm using m1 with fitness value:  0.21946
evolution 1 cost time: 4.5 m
>> 3 of 3 finished 
fitness values of current population: 
0.20389 
0.20438 
0.20633 
>>> 1 of 3 populations finished 
starting new request...
NCI1
4110
37
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6107, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4238, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.9127397272323
cccccc
ddddddd
eeeeeee
0.7805352798053528 0.7737226277372262
{'val': [0.7805352798053528], 'test': [0.7737226277372262]}
0
1
2
3
4
[6.13216233 6.13216233 6.13216209 6.13216209 6.13216233] [0.2000001  0.2000001  0.19999986 0.19999986 0.2000001 ]
generate new algorithm using e1 with fitness value:  0.22628
evolution 1 cost time: 4.066666666666666 m
starting new request...
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
Error in API. 
starting new request...
killed current thread
starting new request...
killed current thread
starting new request...
killed current thread
NCI1
4110
37
Error in API. 
tensor(4.1762, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1192, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8307, device='cuda:0', grad_fn=<NegBackward0>)
Error in API. 
tensor(2.6674, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6110, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.5230, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-1.4216, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1379.915592537986
cccccc
ddddddd
eeeeeee
Error in API. 
0.7810218978102189 0.7732360097323602
{'val': [0.7810218978102189], 'test': [0.7732360097323602]}
0
1
2
3
4
[6.13250518 6.13250518 6.13250542 6.13250518 6.13250518] [0.19999995 0.19999995 0.20000019 0.19999995 0.19999995]
generate new algorithm using m1 with fitness value:  0.22676
evolution 1 cost time: 6.366666666666666 m
>> 1 of 3 finished 
starting new request...
NCI1
4110
37
tensor(4.5613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9600, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8010, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6930, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6095, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6180, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4490, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4450, device='cuda:0', grad_fn=<NegBackward0>)
tensor(-0.8734, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 1713.0859200292164
cccccc
ddddddd
eeeeeee
Error in API. 
0.7766423357664233 0.7832116788321168
{'val': [0.7766423357664233], 'test': [0.7832116788321168]}
0
1
2
3
4
[5.64395094 5.65233207 5.65439796 5.66426802 5.65262032] [0.19040851 0.19881468 0.20088674 0.21078628 0.19910379]
generate new algorithm using e1 with fitness value:  0.21679
evolution 1 cost time: 4.566666666666666 m
starting new request...
Error in API. 
starting new request...
4110
37
================
lr: 0.01
num_features: 37
hidden_dim: 32
num_gc_layers: 3
================
tensor(4.8855, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5527, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3024, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1746, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9115, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7270, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6244, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5467, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6368, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5494, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3619, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2022, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2032, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3553, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2141, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2068, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4440, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4263, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1203, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1217, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9422, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8872, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.9863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1335, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2917, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.1008, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8245, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.8679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.6890, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.7618, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.7773, device='cuda:0', grad_fn=<NegBackward0>)
tensor(0.2772, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 418.2453191081683
[1.73988981 2.07514514 5.17169196 2.90822274 1.73988986] [0. 0. 1. 0. 0.]
tensor(4.9134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9148, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.8496, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7323, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5093, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6919, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6370, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6467, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6243, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7260, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5934, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5088, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6032, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7011, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5453, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4741, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5810, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5941, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5058, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6262, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6039, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5351, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7301, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5363, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4825, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5909, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4267, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.2659, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 2, Loss 572.8698872508425
[2.83573941 2.96251358 4.62611464 3.44087233 2.83573937] [0. 0. 1. 0. 0.]
tensor(4.4042, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4390, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4106, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4977, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5850, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5164, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5121, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5908, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6369, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5572, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4554, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6118, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5970, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5405, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5185, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4482, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4594, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4720, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4959, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4557, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5999, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5853, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5129, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4432, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4717, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6457, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6255, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5293, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5529, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3528, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0576, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 3, Loss 562.305654150067
[2.64136733 2.80343263 4.60655662 3.36865446 2.6413673 ] [0. 0. 1. 0. 0.]
tensor(4.5273, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5052, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5524, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4214, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4325, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6329, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3994, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5658, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4674, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4729, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5393, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6292, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4659, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4178, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5508, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4159, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3498, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4180, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4303, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5597, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5078, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5359, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4573, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4885, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5545, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5600, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5072, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3757, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4080, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4045, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7937, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 4, Loss 556.9391217520742
[2.60287867 2.75377839 4.49780648 3.32827769 2.60287864] [0. 0. 1. 0. 0.]
tensor(4.5261, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3865, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4240, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6145, device='cuda:0', grad_fn=<NegBackward0>)
4110
37
================
lr: 0.01
num_features: 37
hidden_dim: 32
num_gc_layers: 3
================
tensor(4.9059, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5529, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3688, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.0921, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1604, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9432, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1882, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9219, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.9777, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.7137, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6793, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.8547, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6278, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6915, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6156, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4059, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5851, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6856, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.6074, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4448, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4472, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4174, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.5825, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4753, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4530, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.4039, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2447, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2293, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.3582, device='cuda:0', grad_fn=<NegBackward0>)
tensor(3.2174, device='cuda:0', grad_fn=<NegBackward0>)
tensor(0.9510, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 1, Loss 466.14863582090896
[3.77948264 2.17734006 5.10015617 3.13072327 1.87821063] [0. 0. 1. 0. 0.]
tensor(5.0068, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7767, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7058, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5727, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7348, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7362, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.9023, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6668, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6964, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6817, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6837, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6914, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6029, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5668, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5085, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5535, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5829, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5614, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4991, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5209, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6557, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5973, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6842, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5589, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5429, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6288, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5117, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6073, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5174, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4880, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0201, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 2, Loss 575.2605337374138
[3.84490217 2.89875865 4.83009182 3.58177185 2.71743349] [0. 0. 1. 0. 0.]
tensor(4.4837, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4284, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6802, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5809, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5286, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5317, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4193, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5041, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4705, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4140, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4745, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4696, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5180, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4797, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4110, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4911, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5138, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4625, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4695, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4209, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.7249, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5404, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5928, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6001, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5414, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4494, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4858, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5680, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4086, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4333, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8711, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 3, Loss 559.9857485438838
[3.72002363 2.88470619 4.66553627 3.6059571  2.74116758] [0. 0. 1. 0. 0.]
tensor(4.3121, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4659, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4400, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4829, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3836, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5047, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4651, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5676, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5055, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4509, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4882, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5393, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5274, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4978, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4581, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5887, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5021, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5327, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4568, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5161, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4329, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5809, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4108, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4753, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6265, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5174, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5649, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5334, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5467, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4385, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4999, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4078, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0478, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 4, Loss 558.3287153244019
[3.72224607 2.7623336  4.60570662 3.58278172 2.59607553] [0. 0. 1. 0. 0.]
tensor(4.3316, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4852, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4890, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5065, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5500, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5081, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4679, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4998, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4857, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4816, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4526, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4339, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4760, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4227, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6078, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4732, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4487, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4718, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4550, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3076, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3934, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5409, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4942, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5395, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5061, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4778, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4032, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5627, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4429, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3257, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4819, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.1614, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 5, Loss 555.3171954299464
[3.71204938 2.64778042 4.72502163 3.47217819 2.47206446] [0. 0. 1. 0. 0.]
tensor(4.4164, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4521, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3384, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5393, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5419, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4305, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4739, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6624, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4864, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5544, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4818, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3939, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4831, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5003, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5002, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5992, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4501, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3615, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4342, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5740, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5276, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4080, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4093, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4568, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4619, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4373, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5438, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3936, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3720, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4584, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4279, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8283, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 6, Loss 555.9541019092907
[3.69805741 2.63570186 4.67158794 3.5399674  2.4525904 ] [0. 0. 1. 0. 0.]
tensor(4.3862, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4353, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5202, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4141, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5011, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3914, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4980, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3843, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4565, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3776, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5094, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5339, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4037, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5072, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2643, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6026, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3775, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4508, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5169, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3742, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3710, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4580, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5657, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3845, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3949, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4930, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5056, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4168, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7059, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 7, Loss 553.2789833690181
[3.63720584 2.58472855 4.6219259  3.59598133 2.42326106] [0. 0. 1. 0. 0.]
tensor(4.3765, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4755, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3971, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4519, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5990, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4926, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5813, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4547, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6344, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3993, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4663, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3643, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5283, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4254, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4270, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5819, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5769, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3845, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4102, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4714, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4652, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4570, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4811, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3201, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5092, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3450, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4142, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4517, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4010, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4138, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.4177, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 8, Loss 553.6740630756725
[3.70091493 2.55052018 4.72225652 3.66025424 2.38162586] [0. 0. 1. 0. 0.]
tensor(4.4456, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5704, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4143, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4707, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3839, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4333, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5369, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4901, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5504, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4904, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4922, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4058, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3949, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3314, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5706, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5750, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4908, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3969, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4483, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4989, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3647, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5305, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6763, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6373, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4410, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5006, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4742, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2782, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2233, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3006, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.9958, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 9, Loss 554.4588704398184
[3.63901871 2.56417779 4.56811053 3.56477717 2.39397049] [0. 0. 1. 0. 0.]
tensor(4.3855, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2918, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5066, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4219, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5458, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4653, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4392, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4730, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4797, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3769, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5648, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5228, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4480, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4718, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4710, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4056, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3768, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3843, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4646, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4437, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5207, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4516, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4177, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4637, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4232, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4439, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4718, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4066, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4617, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3725, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4297, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7579, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 10, Loss 552.7951583573313
[3.58542119 2.46754466 4.73633453 3.72441159 2.25645341] [0. 0. 1. 0. 0.]
tensor(4.5082, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2902, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4559, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3578, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5641, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3645, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5032, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4309, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3954, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4236, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4937, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3485, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4788, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4037, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5098, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4057, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3794, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5007, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5359, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3904, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5089, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3795, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4080, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3801, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6056, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4673, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4009, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3392, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4418, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.4261, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 11, Loss 551.762683911757
[3.61595195 2.60445864 4.6710528  3.81449631 2.39529988] [0. 0. 1. 0. 0.]
tensor(4.4694, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3695, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3900, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4243, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4311, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5969, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3302, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4505, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4508, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5033, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5300, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3849, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5394, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4063, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4493, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4864, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5257, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4704, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3646, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4472, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5049, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5370, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4736, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2559, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4487, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3603, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4820, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4160, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3739, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4036, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8657, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 12, Loss 552.486209898284
[3.66055581 2.47174481 4.64480652 3.62468835 2.24919973] [0. 0. 1. 0. 0.]
tensor(4.2013, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3876, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3811, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5206, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4846, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6439, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4137, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5081, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3177, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4534, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3703, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4891, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4148, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4726, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5299, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4965, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2222, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4957, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3930, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5760, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4241, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3138, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4737, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4127, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3777, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6271, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4371, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4016, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4405, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3259, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3246, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.9785, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 13, Loss 551.0046515609279
[3.78982135 2.47805687 4.73982109 3.7848194  2.21855426] [0. 0. 1. 0. 0.]
tensor(4.4211, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4021, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2337, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4779, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5949, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6552, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4664, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4980, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3025, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4963, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6142, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5163, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4130, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4558, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3682, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5339, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4713, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4081, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3910, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4028, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5260, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3946, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4683, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3859, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3843, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4827, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4658, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4291, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2747, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4237, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.9313, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 14, Loss 551.4428530750853
[3.67226008 2.49369638 4.69236912 3.7851633  2.25711986] [0. 0. 1. 0. 0.]
tensor(4.4012, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5013, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5342, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5155, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3110, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5513, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4486, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4923, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5451, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4480, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4055, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5327, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4100, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5929, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5143, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3967, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4166, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5580, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4524, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4546, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5693, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4830, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4599, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4080, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3915, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4579, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3601, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4534, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3756, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3250, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2654, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0995, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 15, Loss 554.1068425756512
[3.78148498 2.45744906 4.70985556 3.83701658 2.23307323] [0. 0. 1. 0. 0.]
tensor(4.3313, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4998, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3702, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6534, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4197, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5130, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5515, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3733, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5076, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3612, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3781, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4251, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3868, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5205, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3675, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3628, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4005, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3476, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4177, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4637, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3977, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4144, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4463, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4448, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4455, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3839, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4860, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3758, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5115, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5175, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3454, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2794, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7694, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 16, Loss 550.3731201778759
[3.71281317 2.55938104 4.69743068 3.9720804  2.3272684 ] [0. 0. 1. 0. 0.]
tensor(4.3336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4691, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4469, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3948, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4033, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5989, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5626, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3875, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2927, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4661, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4239, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4407, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4476, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4116, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4116, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4385, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5515, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4291, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3698, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4736, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3193, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4444, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1941, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4736, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4113, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4489, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5013, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5794, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4015, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3492, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3927, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3458, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7426, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 17, Loss 550.0337552374059
[3.65529442 2.41541958 4.6475623  3.95073996 2.16486291] [0. 0. 1. 0. 0.]
tensor(4.4134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4933, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3227, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3092, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4551, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4385, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3646, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4543, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3169, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5413, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3656, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3240, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4229, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3602, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4111, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3030, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4654, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4322, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4265, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3602, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3220, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3460, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5341, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3719, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3489, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3279, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3760, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5938, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4731, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5083, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3512, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.1023, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 18, Loss 547.1953462831901
[3.66249231 2.61178061 4.56392683 4.03096008 2.38425211] [0. 0. 1. 0. 0.]
tensor(4.3162, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4960, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4198, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5909, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3156, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5029, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4519, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4463, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4775, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4474, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5170, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4734, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4683, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4083, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5104, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5244, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4523, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2830, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3420, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3307, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2936, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3759, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3514, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3932, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3329, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3506, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4622, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4660, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4337, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3734, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4329, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4221, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7636, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 19, Loss 549.4492814613111
[3.63044579 2.42607832 4.73155805 3.84700438 2.12413924] [0. 0. 1. 0. 0.]
tensor(4.2004, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4625, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3972, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3866, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2576, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6401, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3244, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5097, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2389, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3215, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2962, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3360, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4691, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4246, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2778, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3999, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2806, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2909, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4991, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3205, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3600, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3103, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3893, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5442, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2354, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5318, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6186, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4305, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4412, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3416, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3356, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7786, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 20, Loss 545.5493086034602
cccccc
ddddddd
eeeeeee
0.7912408759124087 0.786131386861314
[4.39443377 4.24233212 4.96323333 4.54056944 4.09642765] [0. 0. 1. 0. 0.]
tensor(4.2040, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4916, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3056, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4460, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4118, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4051, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4629, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3471, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3759, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4787, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4199, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3023, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3334, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2943, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3255, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2516, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4292, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4779, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3605, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2773, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4207, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4179, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4576, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5152, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4977, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1707, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3590, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3176, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4673, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3529, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4207, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3996, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6032, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 21, Loss 544.4756770061724
[3.73440729 2.39879254 4.74018465 3.80680445 2.14322042] [0. 0. 1. 0. 0.]
tensor(4.1659, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3607, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4449, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3835, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5585, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5406, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4565, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4112, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4315, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5014, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3866, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4362, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3206, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4778, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1244, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3806, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3907, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3282, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4065, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3042, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3745, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4304, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3895, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5053, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3085, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4457, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4508, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4674, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3768, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2945, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3659, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4175, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6489, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 22, Loss 546.2004984292117
[3.60620267 2.42643949 4.62921415 3.93521861 2.14332342] [0. 0. 1. 0. 0.]
tensor(4.2920, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1739, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3475, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3876, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3270, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4106, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5569, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2910, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3006, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.6067, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4328, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3661, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3269, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3533, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4229, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3627, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3959, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3528, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3560, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3719, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3684, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4379, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4473, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4527, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3057, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4338, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2477, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4352, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2553, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3681, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7198, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 23, Loss 543.3142419800614
[3.62237334 2.35526552 4.6741647  3.83760667 2.10167718] [0. 0. 1. 0. 0.]
tensor(4.3201, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4677, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3482, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4021, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4633, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5309, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2641, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4801, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5158, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4541, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3889, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4199, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3153, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4398, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3831, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3263, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2959, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2984, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5374, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4197, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3734, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3420, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3241, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4996, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3065, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5467, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4879, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4255, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3082, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4331, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3437, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0385, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 24, Loss 547.1197591983911
[3.66129364 2.38942466 4.70846844 3.89006553 2.09411154] [0. 0. 1. 0. 0.]
tensor(4.4505, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3899, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3244, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4935, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4504, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5039, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5116, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4822, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4925, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4645, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3257, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4180, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4241, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3727, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4985, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3469, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3950, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3439, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3305, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5067, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3489, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3162, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5695, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4776, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3833, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4909, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3526, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4122, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3277, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3141, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3935, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8135, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 25, Loss 548.9389684778271
[3.66848949 2.35169475 4.65484217 3.8472603  2.05042539] [0. 0. 1. 0. 0.]
tensor(4.3190, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3073, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3745, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2569, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3492, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5729, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4529, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4349, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3419, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4425, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4204, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3721, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3885, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3577, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3605, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3768, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2924, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3339, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5653, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3083, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3566, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4137, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4121, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3186, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3495, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4773, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3851, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2838, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3914, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3998, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6977, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 26, Loss 543.6085016871943
[3.63828448 2.39118239 4.72583635 3.83112488 2.1021235 ] [0. 0. 1. 0. 0.]
tensor(4.3674, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3755, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4480, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4379, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4715, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3965, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3346, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3175, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4916, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3761, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3838, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1136, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3074, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4118, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4795, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4640, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4696, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2501, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3252, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2775, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4615, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4489, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4770, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5057, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2223, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2842, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3138, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3698, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3051, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3990, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4267, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7528, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 27, Loss 544.4247020663637
[3.61449303 2.32848522 4.65373135 3.73279749 2.03540507] [0. 0. 1. 0. 0.]
tensor(4.4537, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2417, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2559, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4824, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3408, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3629, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4010, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3815, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3195, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4210, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2840, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3756, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1724, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4627, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5057, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3217, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4754, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3759, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3571, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3875, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3918, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3895, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4731, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4309, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3204, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3889, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3440, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3943, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3543, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4818, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2301, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3691, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7631, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 28, Loss 543.5715507160534
[3.63676177 2.30350518 4.74130712 3.72436067 1.99762152] [0. 0. 1. 0. 0.]
tensor(4.4405, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3027, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2830, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3107, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3196, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4868, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3594, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4375, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2698, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3482, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2947, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5541, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3981, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3394, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3644, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4075, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5178, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2875, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4303, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3386, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2509, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4841, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3555, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4429, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3075, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4314, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5239, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3406, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4660, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2439, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3073, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3364, device='cuda:0', grad_fn=<NegBackward0>)
tensor(2.0400, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 29, Loss 543.8218597498807
[3.63305099 2.32035903 4.63403954 3.76776511 1.98469807] [0. 0. 1. 0. 0.]
tensor(4.4014, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2075, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2681, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3819, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5199, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4539, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2655, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4227, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4862, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3318, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4018, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3125, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3677, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2995, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3997, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3401, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4659, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3293, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4295, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3064, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4119, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4391, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4467, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5095, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3603, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4527, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3045, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5382, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3501, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2014, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2805, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8055, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 30, Loss 544.183433561614
[3.65641757 2.35010038 4.74498538 3.82435063 1.9864388 ] [0. 0. 1. 0. 0.]
tensor(4.2376, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1943, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2725, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3964, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5274, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2694, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2432, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4351, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5808, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2786, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3693, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4303, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2983, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3751, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3793, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3017, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2666, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2610, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1758, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3663, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3885, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2353, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4053, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4188, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2432, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3715, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4893, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4222, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3145, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2554, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4464, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6134, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 31, Loss 539.9598745143775
[3.70341894 2.43752517 4.70271315 3.80002826 2.10777484] [0. 0. 1. 0. 0.]
tensor(4.2507, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2968, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3218, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5160, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3872, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4100, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4937, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3535, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4141, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3158, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4207, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4358, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2030, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3561, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3453, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3662, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3664, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2320, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3896, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2924, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3066, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4438, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3858, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3200, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4003, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4770, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4648, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4558, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2690, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1922, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2941, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2867, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.1617, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 32, Loss 541.4402170181274
[3.68235915 2.29693358 4.75389814 3.93537395 1.93749365] [0. 0. 1. 0. 0.]
tensor(4.1345, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3449, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4264, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3591, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3027, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3941, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4144, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4326, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2550, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4246, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2759, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2635, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3596, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4489, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3747, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3825, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4017, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3556, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2977, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3431, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3297, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1863, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4323, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4317, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4332, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4022, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3563, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3663, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1732, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3665, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3133, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.7694, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 33, Loss 540.3115039449749
[3.71739241 2.3970092  4.76490266 3.99253287 2.02498823] [0. 0. 1. 0. 0.]
tensor(4.3700, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1600, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3190, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2528, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3938, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2580, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3171, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4264, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4187, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3917, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4035, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1883, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4179, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3497, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2793, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4676, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2778, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3345, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4562, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2387, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4953, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4361, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3819, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4213, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2660, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3697, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4577, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3651, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3245, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4141, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2694, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.3837, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 34, Loss 540.8811483383179
[3.6111146  2.27597622 4.56563078 4.0144202  1.94664807] [0. 0. 1. 0. 0.]
tensor(4.4163, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1946, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5272, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3972, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2964, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4616, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4478, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3793, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2814, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3176, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3198, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3245, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2478, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3426, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5015, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4747, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4367, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3883, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3231, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3360, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4993, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4441, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4460, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3294, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2571, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4870, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3803, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4684, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2938, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2061, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3648, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6378, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 35, Loss 543.7924467361335
[3.74143893 2.46090589 4.63538109 3.99121976 2.15482487] [0. 0. 1. 0. 0.]
tensor(4.2309, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2980, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2336, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4796, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3843, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4729, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3358, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3102, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2973, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3618, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2320, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3363, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2799, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3322, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2855, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3785, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3877, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1847, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2615, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3823, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2579, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3974, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3058, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3846, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3317, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2927, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2887, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4674, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3953, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2503, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3504, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2849, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8015, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 36, Loss 537.8682411800731
[3.69819154 2.35810127 4.62278107 3.91978305 1.99444229] [0. 0. 1. 0. 0.]
tensor(4.2439, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3848, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2220, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4370, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4062, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4552, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3893, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4049, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3929, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3268, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4281, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4214, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4220, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4418, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5023, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3261, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3485, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3419, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3146, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3269, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3520, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2773, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3976, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4088, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4774, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3948, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5073, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3044, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3975, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4116, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2137, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.5003, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 37, Loss 543.8232542890491
[3.68001178 2.2671988  4.53900746 3.87530691 1.861616  ] [0. 0. 1. 0. 0.]
tensor(4.1478, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2369, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1792, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3862, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1723, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4319, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3301, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5395, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2820, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2314, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3676, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2267, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2415, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4155, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3050, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4347, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4665, device='cuda:0', grad_fn=<NegBackward0>)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/home/xtanghao/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
tensor(4.3483, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1351, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3320, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2084, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4099, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4486, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5055, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4329, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3057, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2377, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3048, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3666, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2838, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3548, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2990, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.5383, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 38, Loss 537.3530785676205
[3.72598103 2.37302545 4.70263556 3.9964259  1.99255276] [0. 0. 1. 0. 0.]
tensor(4.2858, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2711, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2828, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2767, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5657, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4363, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2767, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4152, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3262, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4115, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4934, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3920, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5740, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4003, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4328, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5462, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3246, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4131, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2463, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3881, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3613, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2335, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4205, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3874, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4187, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3152, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3442, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4134, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.1633, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2918, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2600, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.8725, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 39, Loss 542.5240412047415
[3.68993834 2.35047552 4.60215364 3.84614103 1.96571272] [0. 0. 1. 0. 0.]
tensor(4.4055, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2983, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3224, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4258, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3150, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3916, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3654, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3937, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2840, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3026, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2974, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3966, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2671, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2705, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3928, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4214, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2927, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3801, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3536, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4125, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2373, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3915, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2501, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4802, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.5040, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3222, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3215, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3703, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.4119, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2479, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.3121, device='cuda:0', grad_fn=<NegBackward0>)
tensor(4.2397, device='cuda:0', grad_fn=<NegBackward0>)
tensor(1.6768, device='cuda:0', grad_fn=<NegBackward0>)
Epoch 40, Loss 540.1641828652585
cccccc
ddddddd
eeeeeee
0.7681265206812651 0.7708029197080293
[4.68548618 4.42016322 5.10662992 4.63298866 4.44720527] [0. 0. 1. 0. 0.]
